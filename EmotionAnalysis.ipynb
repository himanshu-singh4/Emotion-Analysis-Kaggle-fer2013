{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EmotionAnalysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZbNdIbLATsbI","colab_type":"code","outputId":"ecdca875-a9d5-4863-851b-90d64d6f7caa","executionInfo":{"status":"ok","timestamp":1584944987270,"user_tz":-330,"elapsed":6953,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import numpy as np\n","import pandas as pd\n","import keras\n","import cv2  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ApE2PnU1YO9k","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n","from keras.losses import categorical_crossentropy\n","from keras.optimizers import adam\n","from keras.regularizers import l2\n","from keras.utils import np_utils\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5k5yNNdaZJKh","colab_type":"code","outputId":"0e8cd107-d7cb-494d-c41d-d8b60acf2856","executionInfo":{"status":"ok","timestamp":1584945030154,"user_tz":-330,"elapsed":37994,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b5PYtbamZvYk","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSUfovAEaXCY","colab_type":"code","outputId":"72265dcb-1b02-49d8-d572-87fa3cbbc795","executionInfo":{"status":"ok","timestamp":1577190772782,"user_tz":-330,"elapsed":29114,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCk6gm_Z9iO-YyYJ5P8bVuPC_OZR14I3EHVt_VKgg=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["! ls gdrive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["'My Drive'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ofMCt_OnZ4Hl","colab_type":"code","outputId":"65403311-9c66-4459-b473-d02e7c11a5f8","executionInfo":{"status":"ok","timestamp":1584945042479,"user_tz":-330,"elapsed":8046,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["sf = pd.read_csv('gdrive/My Drive/Colab Notebooks/fer2013.csv',delimiter=\",\")\n","(sf.Usage==\"Training\").sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28709"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"uh8_iWDXce0g","colab_type":"code","outputId":"424decd1-8fbf-4867-d641-8306b770e09d","executionInfo":{"status":"ok","timestamp":1584945042480,"user_tz":-330,"elapsed":1031,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["sf.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(35887, 3)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"C5BTbzYNaDw9","colab_type":"code","colab":{}},"source":["train = []\n","test = []\n","y_train = []\n","y_test = []\n","for i in range(sf.shape[0]):\n","  if sf.Usage[i] == \"Training\":\n","    train.append(np.array(sf.pixels[i].split(),'float32'))\n","    y_train.append(sf.emotion[i])\n","  elif sf.Usage[i] == \"PublicTest\":\n","    test.append(np.array(sf.pixels[i].split(),'float32'))\n","    y_test.append(sf.emotion[i])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2o0d_UcucSQB","colab_type":"code","outputId":"025059ef-5bc6-40fd-f7fb-506aff32fcbd","executionInfo":{"status":"ok","timestamp":1584945063406,"user_tz":-330,"elapsed":14173,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train = np.array(train,'float32')\n","test = np.array(test,'float32')\n","train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28709, 2304)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"4pk81jR1bnzi","colab_type":"code","colab":{}},"source":["y_train = np.array(y_train,'float32')\n","y_test = np.array(y_test,'float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"suS4URujvFSP","colab_type":"code","colab":{}},"source":["y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFe1iUgimN58","colab_type":"code","colab":{}},"source":["train -= np.mean(train)\n","train /= np.std(train)\n","\n","test -= np.mean(test)\n","test /= np.std(test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHgNmZ3poUlE","colab_type":"code","colab":{}},"source":["num_features = 64\n","IMAGE_SIZE = 48\n","no_of_labels = 7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOtsePtSmUot","colab_type":"code","colab":{}},"source":["train = train.reshape(-1,48,48,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kisgu1xxnwVd","colab_type":"code","colab":{}},"source":["test = test.reshape(-1,48,48,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AWduiUbBRJw","colab_type":"code","outputId":"eaec0e4f-cab0-4263-be75-a86284960335","executionInfo":{"status":"ok","timestamp":1584945069540,"user_tz":-330,"elapsed":1330,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28709, 48, 48, 1)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Q-H2qePC0Bfs","colab_type":"code","colab":{}},"source":["  def swish_activation(x):\n","    return (K.sigmoid(x) * x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GcRkNGA3oEJm","colab_type":"code","colab":{}},"source":["def cnn_model():\n","\n","  model = Sequential()\n","\n","  model.add(Conv2D(64,(3,3), activation=\"relu\", padding=\"same\", input_shape = (IMAGE_SIZE, IMAGE_SIZE, 1)))\n","  model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n","  model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n","  model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n","  model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  model.add(Flatten())\n","\n","  model.add(Dense(64, activation=swish_activation))\n","  model.add(Dropout(0.4))\n","\n","  model.add(Dense(no_of_labels , activation='sigmoid'))\n","  \n","  model.summary()\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d70Pftf7GUcG","colab_type":"code","outputId":"7577a706-2c9e-4f17-d4d5-24e01b0b4412","executionInfo":{"status":"ok","timestamp":1584946182226,"user_tz":-330,"elapsed":1756,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["my_model = cnn_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_73 (Conv2D)           (None, 48, 48, 64)        640       \n","_________________________________________________________________\n","conv2d_74 (Conv2D)           (None, 46, 46, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_37 (MaxPooling (None, 23, 23, 64)        0         \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 23, 23, 64)        0         \n","_________________________________________________________________\n","conv2d_75 (Conv2D)           (None, 23, 23, 128)       73856     \n","_________________________________________________________________\n","conv2d_76 (Conv2D)           (None, 21, 21, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 21, 21, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_38 (MaxPooling (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","conv2d_77 (Conv2D)           (None, 10, 10, 256)       295168    \n","_________________________________________________________________\n","conv2d_78 (Conv2D)           (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","max_pooling2d_39 (MaxPooling (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_79 (Conv2D)           (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","conv2d_80 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_40 (MaxPooling (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 512)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 512)               262656    \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 7)                 903       \n","=================================================================\n","Total params: 5,115,847\n","Trainable params: 5,113,927\n","Non-trainable params: 1,920\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r3vIV1NDsVWm","colab_type":"code","colab":{}},"source":["my_model.compile(loss=categorical_crossentropy,\n","              optimizer=adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuRR8CiAKSwB","colab_type":"code","colab":{}},"source":["from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n","lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n","tensorboard = TensorBoard(log_dir='./logs')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZ_9LwYNKtCA","colab_type":"code","colab":{}},"source":["early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n","checkpointer = ModelCheckpoint(\"weights.h5\", monitor='val_acc', verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0XlvjidAtyS","colab_type":"code","outputId":"38ea25d7-b516-40b9-9115-7e473bea4cad","executionInfo":{"status":"ok","timestamp":1584948711183,"user_tz":-330,"elapsed":1130424,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["my_model.fit(train, y_train,\n","          batch_size=64,\n","          epochs=100,\n","          verbose=1,\n","          validation_data=(test,y_test),\n","          shuffle=True,\n","          callbacks=[lr_reducer, tensorboard, early_stopper, checkpointer])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 28709 samples, validate on 3589 samples\n","Epoch 1/100\n","28709/28709 [==============================] - 31s 1ms/step - loss: 1.9062 - acc: 0.2189 - val_loss: 1.7955 - val_acc: 0.2494\n","\n","Epoch 00001: val_loss did not improve from 1.06267\n","Epoch 2/100\n","28709/28709 [==============================] - 29s 996us/step - loss: 1.7961 - acc: 0.2516 - val_loss: 1.7261 - val_acc: 0.2995\n","\n","Epoch 00002: val_loss did not improve from 1.06267\n","Epoch 3/100\n","28709/28709 [==============================] - 29s 998us/step - loss: 1.6995 - acc: 0.3113 - val_loss: 1.6168 - val_acc: 0.3433\n","\n","Epoch 00003: val_loss did not improve from 1.06267\n","Epoch 4/100\n","28709/28709 [==============================] - 29s 999us/step - loss: 1.5886 - acc: 0.3667 - val_loss: 1.4190 - val_acc: 0.4308\n","\n","Epoch 00004: val_loss did not improve from 1.06267\n","Epoch 5/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.4922 - acc: 0.4125 - val_loss: 1.3927 - val_acc: 0.4447\n","\n","Epoch 00005: val_loss did not improve from 1.06267\n","Epoch 6/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.4327 - acc: 0.4350 - val_loss: 1.3464 - val_acc: 0.4695\n","\n","Epoch 00006: val_loss did not improve from 1.06267\n","Epoch 7/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.3895 - acc: 0.4596 - val_loss: 1.2741 - val_acc: 0.5057\n","\n","Epoch 00007: val_loss did not improve from 1.06267\n","Epoch 8/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.3429 - acc: 0.4835 - val_loss: 1.2744 - val_acc: 0.5116\n","\n","Epoch 00008: val_loss did not improve from 1.06267\n","Epoch 9/100\n","28709/28709 [==============================] - 29s 995us/step - loss: 1.3111 - acc: 0.4979 - val_loss: 1.2989 - val_acc: 0.4971\n","\n","Epoch 00009: val_loss did not improve from 1.06267\n","Epoch 10/100\n","28709/28709 [==============================] - 29s 999us/step - loss: 1.2853 - acc: 0.5129 - val_loss: 1.1656 - val_acc: 0.5486\n","\n","Epoch 00010: val_loss did not improve from 1.06267\n","Epoch 11/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.2585 - acc: 0.5287 - val_loss: 1.2308 - val_acc: 0.5336\n","\n","Epoch 00011: val_loss did not improve from 1.06267\n","Epoch 12/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.2385 - acc: 0.5372 - val_loss: 1.1531 - val_acc: 0.5603\n","\n","Epoch 00012: val_loss did not improve from 1.06267\n","Epoch 13/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.2234 - acc: 0.5472 - val_loss: 1.1671 - val_acc: 0.5531\n","\n","Epoch 00013: val_loss did not improve from 1.06267\n","Epoch 14/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.1962 - acc: 0.5560 - val_loss: 1.1248 - val_acc: 0.5670\n","\n","Epoch 00014: val_loss did not improve from 1.06267\n","Epoch 15/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.1719 - acc: 0.5642 - val_loss: 1.1283 - val_acc: 0.5712\n","\n","Epoch 00015: val_loss did not improve from 1.06267\n","Epoch 16/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.1609 - acc: 0.5680 - val_loss: 1.0948 - val_acc: 0.5932\n","\n","Epoch 00016: val_loss did not improve from 1.06267\n","Epoch 17/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.1417 - acc: 0.5812 - val_loss: 1.1005 - val_acc: 0.5896\n","\n","Epoch 00017: val_loss did not improve from 1.06267\n","Epoch 18/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.1299 - acc: 0.5806 - val_loss: 1.0808 - val_acc: 0.5963\n","\n","Epoch 00018: val_loss did not improve from 1.06267\n","Epoch 19/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.1034 - acc: 0.5940 - val_loss: 1.0718 - val_acc: 0.6013\n","\n","Epoch 00019: val_loss did not improve from 1.06267\n","Epoch 20/100\n","28709/28709 [==============================] - 29s 994us/step - loss: 1.0886 - acc: 0.6005 - val_loss: 1.0328 - val_acc: 0.6091\n","\n","Epoch 00020: val_loss improved from 1.06267 to 1.03280, saving model to weights.best.hdf5\n","Epoch 21/100\n","28709/28709 [==============================] - 29s 995us/step - loss: 1.0720 - acc: 0.6083 - val_loss: 1.0564 - val_acc: 0.6149\n","\n","Epoch 00021: val_loss did not improve from 1.03280\n","Epoch 22/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.0566 - acc: 0.6172 - val_loss: 1.0438 - val_acc: 0.6138\n","\n","Epoch 00022: val_loss did not improve from 1.03280\n","Epoch 23/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 1.0263 - acc: 0.6223 - val_loss: 1.0346 - val_acc: 0.6166\n","\n","Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n","\n","Epoch 00023: val_loss did not improve from 1.03280\n","Epoch 24/100\n","28709/28709 [==============================] - 29s 999us/step - loss: 1.0130 - acc: 0.6331 - val_loss: 1.0114 - val_acc: 0.6280\n","\n","Epoch 00024: val_loss improved from 1.03280 to 1.01143, saving model to weights.best.hdf5\n","Epoch 25/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.9866 - acc: 0.6424 - val_loss: 1.0064 - val_acc: 0.6250\n","\n","Epoch 00025: val_loss improved from 1.01143 to 1.00644, saving model to weights.best.hdf5\n","Epoch 26/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.9749 - acc: 0.6438 - val_loss: 1.0111 - val_acc: 0.6369\n","\n","Epoch 00026: val_loss did not improve from 1.00644\n","Epoch 27/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.9574 - acc: 0.6502 - val_loss: 1.0056 - val_acc: 0.6330\n","\n","Epoch 00027: val_loss improved from 1.00644 to 1.00565, saving model to weights.best.hdf5\n","Epoch 28/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.9409 - acc: 0.6562 - val_loss: 1.0562 - val_acc: 0.6328\n","\n","Epoch 00028: val_loss did not improve from 1.00565\n","Epoch 29/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.9332 - acc: 0.6589 - val_loss: 1.0096 - val_acc: 0.6317\n","\n","Epoch 00029: val_loss did not improve from 1.00565\n","Epoch 30/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.9170 - acc: 0.6665 - val_loss: 1.0635 - val_acc: 0.6233\n","\n","Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n","\n","Epoch 00030: val_loss did not improve from 1.00565\n","Epoch 31/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.8944 - acc: 0.6765 - val_loss: 0.9980 - val_acc: 0.6375\n","\n","Epoch 00031: val_loss improved from 1.00565 to 0.99798, saving model to weights.best.hdf5\n","Epoch 32/100\n","28709/28709 [==============================] - 29s 1000us/step - loss: 0.8723 - acc: 0.6821 - val_loss: 1.0376 - val_acc: 0.6397\n","\n","Epoch 00032: val_loss did not improve from 0.99798\n","Epoch 33/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.8582 - acc: 0.6883 - val_loss: 1.0407 - val_acc: 0.6436\n","\n","Epoch 00033: val_loss did not improve from 0.99798\n","Epoch 34/100\n","28709/28709 [==============================] - 29s 997us/step - loss: 0.8493 - acc: 0.6937 - val_loss: 1.0315 - val_acc: 0.6470\n","\n","Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n","\n","Epoch 00034: val_loss did not improve from 0.99798\n","Epoch 35/100\n","28709/28709 [==============================] - 29s 997us/step - loss: 0.8222 - acc: 0.7022 - val_loss: 1.0318 - val_acc: 0.6517\n","\n","Epoch 00035: val_loss did not improve from 0.99798\n","Epoch 36/100\n","28709/28709 [==============================] - 29s 996us/step - loss: 0.8034 - acc: 0.7085 - val_loss: 1.0398 - val_acc: 0.6414\n","\n","Epoch 00036: val_loss did not improve from 0.99798\n","Epoch 37/100\n","28709/28709 [==============================] - 29s 998us/step - loss: 0.7948 - acc: 0.7139 - val_loss: 1.0396 - val_acc: 0.6431\n","\n","Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n","\n","Epoch 00037: val_loss did not improve from 0.99798\n","Epoch 38/100\n","28709/28709 [==============================] - 29s 1ms/step - loss: 0.7621 - acc: 0.7242 - val_loss: 1.0942 - val_acc: 0.6414\n","\n","Epoch 00038: val_loss did not improve from 0.99798\n","Epoch 39/100\n","28709/28709 [==============================] - 29s 998us/step - loss: 0.7599 - acc: 0.7259 - val_loss: 1.1020 - val_acc: 0.6459\n","\n","Epoch 00039: val_loss did not improve from 0.99798\n","Epoch 00039: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7d23b721d0>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"uRvlDljU97oC","colab_type":"code","colab":{}},"source":["from keras.constraints import maxnorm\n","from keras.layers import GlobalAveragePooling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","    featurewise_center= False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    rotation_range=10,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=False\n",")\n","\n","datagen.fit(train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8kYz7Nc-GGR","colab_type":"code","outputId":"104f1d53-932c-4c5e-a750-baaf6a013492","executionInfo":{"status":"ok","timestamp":1584955442667,"user_tz":-330,"elapsed":1318,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":728}},"source":["augmented_model = cnn_model()"],"execution_count":71,"outputs":[{"output_type":"stream","text":["Model: \"sequential_17\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_123 (Conv2D)          (None, 48, 48, 64)        640       \n","_________________________________________________________________\n","conv2d_124 (Conv2D)          (None, 48, 48, 32)        18464     \n","_________________________________________________________________\n","max_pooling2d_62 (MaxPooling (None, 24, 24, 32)        0         \n","_________________________________________________________________\n","conv2d_125 (Conv2D)          (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","conv2d_126 (Conv2D)          (None, 24, 24, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_63 (MaxPooling (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","conv2d_127 (Conv2D)          (None, 12, 12, 96)        55392     \n","_________________________________________________________________\n","conv2d_128 (Conv2D)          (None, 10, 10, 96)        83040     \n","_________________________________________________________________\n","max_pooling2d_64 (MaxPooling (None, 5, 5, 96)          0         \n","_________________________________________________________________\n","conv2d_129 (Conv2D)          (None, 5, 5, 128)         110720    \n","_________________________________________________________________\n","conv2d_130 (Conv2D)          (None, 3, 3, 128)         147584    \n","_________________________________________________________________\n","max_pooling2d_65 (MaxPooling (None, 1, 1, 128)         0         \n","_________________________________________________________________\n","flatten_16 (Flatten)         (None, 128)               0         \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dropout_47 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 7)                 455       \n","=================================================================\n","Total params: 479,975\n","Trainable params: 479,975\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eKxi6tPh-UZt","colab_type":"code","colab":{}},"source":["augmented_model.compile(loss='binary_crossentropy',\n","              optimizer='adam' ,\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1irinU6SsgBL","colab_type":"code","outputId":"ccd269e2-92ac-4b27-9cc2-d662e150fdcb","executionInfo":{"status":"ok","timestamp":1584955613475,"user_tz":-330,"elapsed":163116,"user":{"displayName":"Himanshu Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZlNvC079WsoQKYkpgJzVSCB0FMPu4hK_QdVFTTQ=s64","userId":"16757715009564006896"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["augmented_model.fit(train, y_train,\n","          batch_size=128,\n","          epochs=100,\n","          verbose=1,\n","          validation_data=(test,y_test),\n","          shuffle=True,\n","          callbacks=[lr_reducer, tensorboard, early_stopper, checkpointer])"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Train on 28709 samples, validate on 3589 samples\n","Epoch 1/100\n","28709/28709 [==============================] - 12s 407us/step - loss: 0.4095 - acc: 0.8518 - val_loss: 0.3835 - val_acc: 0.8571\n","\n","Epoch 00001: val_acc improved from 0.65227 to 0.85714, saving model to weights.h5\n","Epoch 2/100\n","28709/28709 [==============================] - 10s 356us/step - loss: 0.3761 - acc: 0.8596 - val_loss: 0.3271 - val_acc: 0.8731\n","\n","Epoch 00002: val_acc improved from 0.85714 to 0.87310, saving model to weights.h5\n","Epoch 3/100\n","28709/28709 [==============================] - 10s 358us/step - loss: 0.3198 - acc: 0.8770 - val_loss: 0.2910 - val_acc: 0.8841\n","\n","Epoch 00003: val_acc improved from 0.87310 to 0.88405, saving model to weights.h5\n","Epoch 4/100\n","28709/28709 [==============================] - 10s 356us/step - loss: 0.2866 - acc: 0.8861 - val_loss: 0.2793 - val_acc: 0.8879\n","\n","Epoch 00004: val_acc improved from 0.88405 to 0.88791, saving model to weights.h5\n","Epoch 5/100\n","28709/28709 [==============================] - 10s 356us/step - loss: 0.2656 - acc: 0.8931 - val_loss: 0.2698 - val_acc: 0.8899\n","\n","Epoch 00005: val_acc improved from 0.88791 to 0.88986, saving model to weights.h5\n","Epoch 6/100\n","28709/28709 [==============================] - 10s 355us/step - loss: 0.2480 - acc: 0.9002 - val_loss: 0.2598 - val_acc: 0.8960\n","\n","Epoch 00006: val_acc improved from 0.88986 to 0.89603, saving model to weights.h5\n","Epoch 7/100\n","28709/28709 [==============================] - 10s 356us/step - loss: 0.2306 - acc: 0.9075 - val_loss: 0.2580 - val_acc: 0.8980\n","\n","Epoch 00007: val_acc improved from 0.89603 to 0.89798, saving model to weights.h5\n","Epoch 8/100\n","28709/28709 [==============================] - 10s 355us/step - loss: 0.2112 - acc: 0.9153 - val_loss: 0.2581 - val_acc: 0.8974\n","\n","Epoch 00008: val_acc did not improve from 0.89798\n","Epoch 9/100\n","28709/28709 [==============================] - 10s 354us/step - loss: 0.1905 - acc: 0.9240 - val_loss: 0.2634 - val_acc: 0.8981\n","\n","Epoch 00009: val_acc improved from 0.89798 to 0.89814, saving model to weights.h5\n","Epoch 10/100\n","28709/28709 [==============================] - 10s 355us/step - loss: 0.1698 - acc: 0.9329 - val_loss: 0.2780 - val_acc: 0.8964\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n","\n","Epoch 00010: val_acc did not improve from 0.89814\n","Epoch 11/100\n","28709/28709 [==============================] - 10s 353us/step - loss: 0.1410 - acc: 0.9452 - val_loss: 0.3012 - val_acc: 0.8955\n","\n","Epoch 00011: val_acc did not improve from 0.89814\n","Epoch 12/100\n","28709/28709 [==============================] - 10s 354us/step - loss: 0.1189 - acc: 0.9544 - val_loss: 0.3476 - val_acc: 0.8919\n","\n","Epoch 00012: val_acc did not improve from 0.89814\n","Epoch 13/100\n","28709/28709 [==============================] - 10s 355us/step - loss: 0.1010 - acc: 0.9619 - val_loss: 0.3499 - val_acc: 0.8923\n","\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n","\n","Epoch 00013: val_acc did not improve from 0.89814\n","Epoch 14/100\n","28709/28709 [==============================] - 10s 356us/step - loss: 0.0763 - acc: 0.9717 - val_loss: 0.4293 - val_acc: 0.8902\n","\n","Epoch 00014: val_acc did not improve from 0.89814\n","Epoch 15/100\n","28709/28709 [==============================] - 10s 355us/step - loss: 0.0692 - acc: 0.9752 - val_loss: 0.4504 - val_acc: 0.8902\n","\n","Epoch 00015: val_acc did not improve from 0.89814\n","Epoch 00015: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7af01eadd8>"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"MgmxvwXxtOE5","colab_type":"code","colab":{}},"source":["fer_json = augmented_model.to_json()\n","with open(\"fer.json\", \"w\") as json_file:\n","  json_file.write(fer_json)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"21okl-H9CIJR","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download('fer.json')   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3aB5J8jjnKL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}